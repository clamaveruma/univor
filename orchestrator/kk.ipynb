{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6db278d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">length: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "width: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "height: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "color: blue\n",
       "meta:\n",
       "  owner: Alice\n",
       "  location:\n",
       "    city: Paris\n",
       "    country: France\n",
       "tags:\n",
       "- storage\n",
       "- blue\n",
       "- nam:\n",
       "    large: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    a: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "length: \u001b[1;36m10\u001b[0m\n",
       "width: \u001b[1;36m5\u001b[0m\n",
       "height: \u001b[1;36m3\u001b[0m\n",
       "color: blue\n",
       "meta:\n",
       "  owner: Alice\n",
       "  location:\n",
       "    city: Paris\n",
       "    country: France\n",
       "tags:\n",
       "- storage\n",
       "- blue\n",
       "- nam:\n",
       "    large: \u001b[1;36m0\u001b[0m\n",
       "    a: \u001b[1;36m9\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from box import Box\n",
    "from rich import print as rprint\n",
    "\n",
    "\n",
    "# Create a nested Box object for better demonstration\n",
    "# Add a list to the variable\n",
    "\n",
    "a = Box({\n",
    "    \"length\": 10,\n",
    "    \"width\": 5,\n",
    "    \"height\": 3,\n",
    "    \"color\": \"blue\",\n",
    "    \"meta\": {\n",
    "        \"owner\": \"Alice\",\n",
    "        \"location\": {\"city\": \"Paris\", \"country\": \"France\"}\n",
    "    },\n",
    "    \"tags\": [\"storage\", \"blue\", {\"nam\":{\"large\":0,\"a\":9}}]\n",
    "})\n",
    "\n",
    "rprint(a.to_yaml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "251136d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from box import Box\n",
    "\n",
    "def merge_boxes(a: Box, b: Box, unique_strings_in_lists: bool = True) -> Box:\n",
    "    \"\"\"\n",
    "    Deep merge two Box objects:\n",
    "    - b overrides a.\n",
    "    - Dicts/Boxes are merged recursively.\n",
    "    - Lists:\n",
    "        * Single-key dicts/Boxes with same key → merge recursively\n",
    "        * Strings → append only if not already present (controlled by unique_strings_in_lists)\n",
    "        * Other elements → append\n",
    "    - Scalars/other values: overwritten by b\n",
    "    \"\"\"\n",
    "    result = Box(a.to_dict())\n",
    "\n",
    "    for key, b_val in b.items():\n",
    "        if key not in result:\n",
    "            result[key] = b_val\n",
    "            continue\n",
    "\n",
    "        a_val = result[key]\n",
    "\n",
    "        # Case 1: Both dicts/Boxes → merge recursively\n",
    "        if isinstance(a_val, (Box, dict)) and isinstance(b_val, (Box, dict)):\n",
    "            result[key] = merge_boxes(Box(a_val), Box(b_val), unique_strings_in_lists)\n",
    "\n",
    "        # Case 2: Both lists → merge elements\n",
    "        elif isinstance(a_val, list) and isinstance(b_val, list):\n",
    "            # Build id_map for single-key dicts/Boxes\n",
    "            id_map = {next(iter(item)): i for i, item in enumerate(a_val)\n",
    "                      if isinstance(item, (Box, dict)) and len(item) == 1}\n",
    "\n",
    "            for b_item in b_val:\n",
    "                if isinstance(b_item, (Box, dict)) and len(b_item) == 1:\n",
    "                    b_id = next(iter(b_item))\n",
    "                    if b_id in id_map:\n",
    "                        idx = id_map[b_id]\n",
    "                        a_val[idx] = merge_boxes(Box(a_val[idx]), Box(b_item), unique_strings_in_lists)\n",
    "                    else:\n",
    "                        a_val.append(b_item)\n",
    "                elif isinstance(b_item, str) and unique_strings_in_lists:\n",
    "                    if b_item not in a_val:\n",
    "                        a_val.append(b_item)\n",
    "                else:\n",
    "                    a_val.append(b_item)\n",
    "\n",
    "        # Case 3: Otherwise → overwrite\n",
    "        else:\n",
    "            result[key] = b_val\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a65baba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge2 \n",
    "import copy\n",
    "import json\n",
    "from collections.abc import Mapping\n",
    "from typing import Any, cast\n",
    "\n",
    "\n",
    "def _clone(value: Any) -> Any:\n",
    "    \"\"\"Return a deep copy limited to dict/list primitives.\"\"\"\n",
    "    if isinstance(value, dict):\n",
    "        return {k: _clone(v) for k, v in value.items()}\n",
    "    if isinstance(value, list):\n",
    "        return [_clone(item) for item in value]\n",
    "    return copy.deepcopy(value)\n",
    "\n",
    "\n",
    "def _identify_list_item(item, identifier_keys):\n",
    "    \"\"\"Return a stable identifier for list entries so we can merge compatible items.\"\"\"\n",
    "    if isinstance(item, dict):\n",
    "        for key in identifier_keys:\n",
    "            if key in item:\n",
    "                return (\"key\", key, item[key])\n",
    "        if len(item) == 1:\n",
    "            sole_key = next(iter(item))\n",
    "            return (\"single-key\", sole_key)\n",
    "        try:\n",
    "            return (\"shape\", json.dumps(item, sort_keys=True))\n",
    "        except TypeError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def _merge_lists(\n",
    "    target: list,\n",
    "    source: list,\n",
    "    identifier_keys: tuple[str, ...],\n",
    ") -> list:\n",
    "    \"\"\"Merge two lists with identifier-aware reconciliation.\"\"\"\n",
    "    id_map: dict[tuple, int] = {}\n",
    "    for idx, existing in enumerate(target):\n",
    "        ident = _identify_list_item(existing, identifier_keys)\n",
    "        if ident is not None and ident not in id_map:\n",
    "            id_map[ident] = idx  # Remember where matching dict entries live\n",
    "\n",
    "    for item in source:\n",
    "        ident = _identify_list_item(item, identifier_keys)\n",
    "        if ident is not None and ident in id_map:\n",
    "            idx = id_map[ident]\n",
    "            existing = target[idx]\n",
    "            if isinstance(existing, dict) and isinstance(item, dict):\n",
    "                # Merge matching dict entries in place\n",
    "                target[idx] = merge2(\n",
    "                    existing,\n",
    "                    item,\n",
    "                    identifier_keys,\n",
    "                )\n",
    "                continue\n",
    "        if isinstance(item, str):\n",
    "            # Deduplicate string tags by default\n",
    "            if item not in target:\n",
    "                target.append(item)\n",
    "        else:\n",
    "            # Numbers or nested structures fall here → clone and append\n",
    "            appended = _clone(item)\n",
    "            target.append(appended)\n",
    "            if ident is not None and ident not in id_map and isinstance(appended, dict):\n",
    "                id_map[ident] = len(target) - 1  # Enable future merges for appended dicts\n",
    "    return target\n",
    "\n",
    "\n",
    "def merge2(\n",
    "    a: Mapping,\n",
    "    b: Mapping,\n",
    "    identifier_keys: tuple[str, ...] = (\"id\", \"name\", \"uuid\"),\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Deep merge two dictionaries with deterministic list reconciliation and string deduplication.\n",
    "    \"\"\"\n",
    "    if not isinstance(a, Mapping) or not isinstance(b, Mapping):\n",
    "        raise TypeError(\"merge2 expects mapping inputs\")\n",
    "\n",
    "    result: dict[str, Any] = cast(dict[str, Any], _clone(dict(a)))  # preserve caller input by cloning\n",
    "    other = dict(b)  # shallow copy is fine; we immediately clone elements\n",
    "\n",
    "    for key, b_val in other.items():\n",
    "        if key not in result:\n",
    "            result[key] = _clone(b_val)\n",
    "            continue\n",
    "\n",
    "        a_val = result[key]\n",
    "\n",
    "        if isinstance(a_val, dict) and isinstance(b_val, Mapping):\n",
    "            # Merge nested dictionaries recursively\n",
    "            result[key] = merge2(\n",
    "                a_val,\n",
    "                dict(b_val),\n",
    "                identifier_keys,\n",
    "            )\n",
    "        elif isinstance(a_val, list) and isinstance(b_val, list):\n",
    "            result[key] = _merge_lists(\n",
    "                a_val,\n",
    "                b_val,\n",
    "                identifier_keys,\n",
    "            )\n",
    "        else:\n",
    "            # Scalars or mismatched types → overwrite with b\n",
    "            result[key] = _clone(b_val)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e719bf9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "BoxKeyError",
     "evalue": "'Key name \"items\" is protected'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBoxKeyError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 123\u001b[39m\n\u001b[32m    121\u001b[39m item_one.x = \u001b[32m1\u001b[39m\n\u001b[32m    122\u001b[39m item_one.y = \u001b[32m2\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[43munidentifiable_base\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m = [item_one]\n\u001b[32m    125\u001b[39m unidentifiable_incoming = _new_box()\n\u001b[32m    126\u001b[39m item_two = _new_box()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/univor/.venv/lib/python3.12/site-packages/box/box.py:684\u001b[39m, in \u001b[36mbox.box.Box.__setattr__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mBoxKeyError\u001b[39m: 'Key name \"items\" is protected'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from box import Box\n",
    "\n",
    "\n",
    "def _new_box() -> Box:\n",
    "    \"\"\"Convenience factory to enable dot-based assignments.\"\"\"\n",
    "    return Box(default_box=True, box_dots=True)\n",
    "\n",
    "\n",
    "def _assert_merge(name: str, base: Box, incoming: Box, expected: Box) -> None:\n",
    "    \"\"\"Helper asserting merge2 results and immutability when driven by Box inputs.\"\"\"\n",
    "    base_snapshot = copy.deepcopy(base)\n",
    "    incoming_snapshot = copy.deepcopy(incoming)\n",
    "    result = merge2(base, incoming)\n",
    "    assert result == expected.to_dict(), f\"{name} → unexpected merge result: {result}\"\n",
    "    assert base == base_snapshot, f\"{name} → base mutated\"\n",
    "    assert incoming == incoming_snapshot, f\"{name} → incoming mutated\"\n",
    "\n",
    "\n",
    "# 1. Deduplicate string tags while preserving originals\n",
    "tags_base = _new_box()\n",
    "tags_base.meta.tags = [\"blue\", \"storage\"]\n",
    "tags_incoming = _new_box()\n",
    "tags_incoming.meta.tags = [\"new\", \"blue\"]\n",
    "tags_expected = _new_box()\n",
    "tags_expected.meta.tags = [\"blue\", \"storage\", \"new\"]\n",
    "_assert_merge(\"tags_merge\", tags_base, tags_incoming, tags_expected)\n",
    "\n",
    "\n",
    "# 2. Merge dict items by identifier and recurse into nested dicts\n",
    "service_base = _new_box()\n",
    "service_api = _new_box()\n",
    "service_api.id = \"api\"\n",
    "service_api.port = 80\n",
    "service_api.env.DEBUG = False\n",
    "service_base.services = [service_api]\n",
    "\n",
    "service_incoming = _new_box()\n",
    "incoming_api = _new_box()\n",
    "incoming_api.id = \"api\"\n",
    "incoming_api.env.DEBUG = True\n",
    "incoming_api.env.CACHE = False\n",
    "incoming_worker = _new_box()\n",
    "incoming_worker.id = \"worker\"\n",
    "incoming_worker.port = 9000\n",
    "service_incoming.services = [incoming_api, incoming_worker]\n",
    "\n",
    "service_expected = _new_box()\n",
    "expected_api = _new_box()\n",
    "expected_api.id = \"api\"\n",
    "expected_api.port = 80\n",
    "expected_api.env.DEBUG = True\n",
    "expected_api.env.CACHE = False\n",
    "expected_worker = _new_box()\n",
    "expected_worker.id = \"worker\"\n",
    "expected_worker.port = 9000\n",
    "service_expected.services = [expected_api, expected_worker]\n",
    "\n",
    "_assert_merge(\"service_merge\", service_base, service_incoming, service_expected)\n",
    "\n",
    "\n",
    "# 3. Single-key dicts merge via their key name even without explicit ids\n",
    "feature_base = _new_box()\n",
    "feature_entry = _new_box()\n",
    "feature_entry.feature.enabled = False\n",
    "feature_entry.feature.level = \"beta\"\n",
    "feature_base.policies = [feature_entry]\n",
    "\n",
    "feature_incoming = _new_box()\n",
    "feature_update = _new_box()\n",
    "feature_update.feature.level = \"stable\"\n",
    "feature_incoming.policies = [feature_update]\n",
    "\n",
    "feature_expected = _new_box()\n",
    "feature_expected_entry = _new_box()\n",
    "feature_expected_entry.feature.enabled = False\n",
    "feature_expected_entry.feature.level = \"stable\"\n",
    "feature_expected.policies = [feature_expected_entry]\n",
    "\n",
    "_assert_merge(\"feature_single_key\", feature_base, feature_incoming, feature_expected)\n",
    "\n",
    "\n",
    "# 4. Scalars without identifiers append in order (duplicates allowed)\n",
    "numeric_base = _new_box()\n",
    "numeric_base.thresholds = [1, 2]\n",
    "numeric_incoming = _new_box()\n",
    "numeric_incoming.thresholds = [2, 3]\n",
    "numeric_expected = _new_box()\n",
    "numeric_expected.thresholds = [1, 2, 2, 3]\n",
    "_assert_merge(\"numeric_append\", numeric_base, numeric_incoming, numeric_expected)\n",
    "\n",
    "\n",
    "# 5. Identical dict entries are deduplicated via identifier or shape matching\n",
    "duplicate_rule = _new_box()\n",
    "duplicate_rule.rule.allow = True\n",
    "duplicate_base = _new_box()\n",
    "duplicate_base.rules = [duplicate_rule]\n",
    "duplicate_incoming = _new_box()\n",
    "duplicate_incoming.rules = [duplicate_rule]\n",
    "duplicate_expected = _new_box()\n",
    "expected_rule = _new_box()\n",
    "expected_rule.rule.allow = True\n",
    "duplicate_expected.rules = [expected_rule]\n",
    "_assert_merge(\"duplicate_dict_dedup\", duplicate_base, duplicate_incoming, duplicate_expected)\n",
    "\n",
    "\n",
    "# 6. Nested mapping replaced when incoming type differs\n",
    "override_base = _new_box()\n",
    "override_base.settings.timeout = 30\n",
    "override_base.settings.retries = 2\n",
    "override_incoming = _new_box()\n",
    "override_incoming.settings = 42\n",
    "override_expected = _new_box()\n",
    "override_expected.settings = 42\n",
    "_assert_merge(\"type_override\", override_base, override_incoming, override_expected)\n",
    "\n",
    "\n",
    "# 7. Non-identifiable dict entries append when content diverges\n",
    "unidentifiable_base = _new_box()\n",
    "item_one = _new_box()\n",
    "item_one.x = 1\n",
    "item_one.y = 2\n",
    "unidentifiable_base.items = [item_one]\n",
    "\n",
    "unidentifiable_incoming = _new_box()\n",
    "item_two = _new_box()\n",
    "item_two.x = 2\n",
    "item_two.y = 3\n",
    "unidentifiable_incoming.items = [item_two]\n",
    "\n",
    "unidentifiable_expected = _new_box()\n",
    "expected_item_one = _new_box()\n",
    "expected_item_one.x = 1\n",
    "expected_item_one.y = 2\n",
    "expected_item_two = _new_box()\n",
    "expected_item_two.x = 2\n",
    "expected_item_two.y = 3\n",
    "unidentifiable_expected.items = [expected_item_one, expected_item_two]\n",
    "_assert_merge(\"unidentifiable_append\", unidentifiable_base, unidentifiable_incoming, unidentifiable_expected)\n",
    "\n",
    "\n",
    "print(\"merge2 sanity checks passed ✔\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbe03093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AppConfig(services=[Service(id='api', port=80, env={'DEBUG': True, 'CACHE': False}), Service(id='worker', port=9000, env={})], tags=['prod', 'blue'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Any, TypeVar\n",
    "from pydantic import BaseModel\n",
    "\n",
    "ModelT = TypeVar(\"ModelT\", bound=BaseModel)\n",
    "\n",
    "\n",
    "def merge_basemodels(\n",
    "    base: ModelT,\n",
    "    incoming: ModelT,\n",
    "    identifier_keys: tuple[str, ...] = (\"id\", \"name\", \"uuid\"),\n",
    ") -> ModelT:\n",
    "    \"\"\"Merge two Pydantic models by delegating to merge2 on their Python payloads.\"\"\"\n",
    "    target_type = type(incoming) if type(base) is not type(incoming) else type(base)\n",
    "    merged_payload = merge2(\n",
    "        base.model_dump(mode=\"python\"),\n",
    "        incoming.model_dump(mode=\"python\"),\n",
    "        identifier_keys,\n",
    "    )\n",
    "    return target_type.model_validate(merged_payload)\n",
    "\n",
    "\n",
    "class Service(BaseModel):\n",
    "    id: str\n",
    "    port: int\n",
    "    env: dict[str, Any] = {}\n",
    "\n",
    "\n",
    "class AppConfig(BaseModel):\n",
    "    services: list[Service]\n",
    "    tags: list[str] = []\n",
    "\n",
    "\n",
    "defaults = AppConfig(\n",
    "    services=[Service(id=\"api\", port=80, env={\"DEBUG\": False})],\n",
    "    tags=[\"prod\"],\n",
    ")\n",
    "\n",
    "override = AppConfig(\n",
    "    services=[\n",
    "        Service(id=\"api\", port=80, env={\"DEBUG\": True, \"CACHE\": False}),\n",
    "        Service(id=\"worker\", port=9000, env={}),\n",
    "    ],\n",
    "    tags=[\"prod\", \"blue\"],\n",
    ")\n",
    "\n",
    "merged_config = merge_basemodels(defaults, override)\n",
    "merged_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d95118e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AppConfig(services=[Service(id='api', port=80, env={'DEBUG': True, 'CACHE': False}), Service(id='worker', port=9000, env={})], tags=['prod', 'blue'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deep merge two Pydantic BaseModel instances while preserving model attributes.\n",
    "import copy\n",
    "from typing import Any\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "\n",
    "def _clone_model_value(value: Any) -> Any:\n",
    "    if isinstance(value, BaseModel):\n",
    "        return value.model_copy(deep=True)\n",
    "    if isinstance(value, list):\n",
    "        return [_clone_model_value(item) for item in value]\n",
    "    if isinstance(value, dict):\n",
    "        return {key: _clone_model_value(val) for key, val in value.items()}\n",
    "    return copy.deepcopy(value)\n",
    "\n",
    "\n",
    "\n",
    "def _identify_model_item(item: Any, identifier_keys: tuple[str, ...]) -> Any:\n",
    "    if isinstance(item, BaseModel):\n",
    "        return _identify_model_item(item.model_dump(mode=\"python\"), identifier_keys)\n",
    "    if isinstance(item, dict):\n",
    "        for key in identifier_keys:\n",
    "            if key in item:\n",
    "                return (\"id\", key, item[key])\n",
    "        if len(item) == 1:\n",
    "            return (\"single\", next(iter(item)))\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def _merge_model_list(\n",
    "    current: list[Any],\n",
    "    incoming: list[Any],\n",
    "    identifier_keys: tuple[str, ...],\n",
    ") -> list[Any]:\n",
    "    merged = [_clone_model_value(item) for item in current]\n",
    "    indexed: dict[Any, int] = {}\n",
    "    for idx, item in enumerate(merged):\n",
    "        ident = _identify_model_item(item, identifier_keys)\n",
    "        if ident is not None and ident not in indexed:\n",
    "            indexed[ident] = idx\n",
    "\n",
    "    for item in incoming:\n",
    "        ident = _identify_model_item(item, identifier_keys)\n",
    "        if ident is not None and ident in indexed:\n",
    "            existing_idx = indexed[ident]\n",
    "            merged[existing_idx] = _merge_model_value(\n",
    "                merged[existing_idx],\n",
    "                item,\n",
    "                identifier_keys,\n",
    "            )\n",
    "            continue\n",
    "        if isinstance(item, str):\n",
    "            if item not in merged:\n",
    "                merged.append(item)\n",
    "            continue\n",
    "        cloned = _clone_model_value(item)\n",
    "        merged.append(cloned)\n",
    "        if ident is not None and ident not in indexed:\n",
    "            indexed[ident] = len(merged) - 1\n",
    "    return merged\n",
    "\n",
    "\n",
    "\n",
    "def _merge_model_value(\n",
    "    current: Any,\n",
    "    incoming: Any,\n",
    "    identifier_keys: tuple[str, ...],\n",
    ") -> Any:\n",
    "    if incoming is None:\n",
    "        return None\n",
    "    if current is None:\n",
    "        return _clone_model_value(incoming)\n",
    "    if isinstance(current, BaseModel) and isinstance(incoming, BaseModel):\n",
    "        return _merge_models_preserving(current, incoming, identifier_keys)\n",
    "    if isinstance(current, dict) and isinstance(incoming, dict):\n",
    "        return merge2(current, incoming, identifier_keys)\n",
    "    if isinstance(current, list) and isinstance(incoming, list):\n",
    "        return _merge_model_list(current, incoming, identifier_keys)\n",
    "    return _clone_model_value(incoming)\n",
    "\n",
    "\n",
    "\n",
    "def _merge_models_preserving(\n",
    "    base: BaseModel,\n",
    "    incoming: BaseModel,\n",
    "    identifier_keys: tuple[str, ...],\n",
    ") -> BaseModel:\n",
    "    if type(base) is not type(incoming):\n",
    "        return incoming.model_copy(deep=True)\n",
    "    result = base.model_copy(deep=True)\n",
    "    for field_name in type(result).model_fields:\n",
    "        if not hasattr(incoming, field_name):\n",
    "            continue\n",
    "        base_value = getattr(result, field_name)\n",
    "        incoming_value = getattr(incoming, field_name)\n",
    "        merged_value = _merge_model_value(\n",
    "            base_value,\n",
    "            incoming_value,\n",
    "            identifier_keys,\n",
    "        )\n",
    "        setattr(result, field_name, merged_value)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def merge_basemodels_preserving(\n",
    "    base: ModelT,\n",
    "    incoming: ModelT,\n",
    "    identifier_keys: tuple[str, ...] = (\"id\", \"name\", \"uuid\"),\n",
    ") -> ModelT:\n",
    "    \"\"\"Deep merge two BaseModel instances while keeping model attributes intact.\"\"\"\n",
    "    merged = _merge_models_preserving(base, incoming, identifier_keys)\n",
    "    return type(merged).model_validate(merged.model_dump(mode=\"python\"))\n",
    "\n",
    "\n",
    "\n",
    "merged_config_preserving = merge_basemodels_preserving(defaults, override)\n",
    "merged_config_preserving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47144dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge_basemodels_preserving comprehensive scenario passed ✔\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "from pydantic import BaseModel\n",
    "import yaml\n",
    "\n",
    "\n",
    "\n",
    "def _dump_model(model: BaseModel) -> dict[str, Any]:\n",
    "    return model.model_dump(mode=\"python\")\n",
    "\n",
    "\n",
    "\n",
    "def _assert_model_merge(\n",
    "    name: str,\n",
    "    base_model: BaseModel,\n",
    "    incoming_model: BaseModel,\n",
    "    expected_dump: dict[str, Any],\n",
    ") -> None:\n",
    "    base_snapshot = _dump_model(base_model)\n",
    "    incoming_snapshot = _dump_model(incoming_model)\n",
    "    merged = merge_basemodels_preserving(base_model, incoming_model)\n",
    "    merged_dump = _dump_model(merged)\n",
    "    assert merged_dump == expected_dump, f\"{name}: unexpected merge result: {merged_dump}\"\n",
    "    assert _dump_model(base_model) == base_snapshot, f\"{name}: base mutated\"\n",
    "    assert _dump_model(incoming_model) == incoming_snapshot, f\"{name}: incoming mutated\"\n",
    "\n",
    "\n",
    "\n",
    "class Service(BaseModel):\n",
    "    id: str\n",
    "    port: int\n",
    "    env: dict[str, Any] = {}\n",
    "\n",
    "\n",
    "\n",
    "class Rollout(BaseModel):\n",
    "    feature: dict[str, Any]\n",
    "\n",
    "\n",
    "\n",
    "class AppSettings(BaseModel):\n",
    "    payload: dict[str, Any] | int\n",
    "\n",
    "\n",
    "\n",
    "class ComplexConfig(BaseModel):\n",
    "    services: list[Service]\n",
    "    policies: list[Rollout]\n",
    "    thresholds: list[int]\n",
    "    tags: list[str]\n",
    "    settings: AppSettings\n",
    "    metadata: dict[str, Any]\n",
    "    alerts: list[dict[str, Any]]\n",
    "    rules: list[dict[str, Any]]\n",
    "\n",
    "\n",
    "\n",
    "COMPLEX_DEFAULTS_YAML = \"\"\"\n",
    "services:\n",
    "  - id: api\n",
    "    port: 80\n",
    "    env:\n",
    "      DEBUG: false\n",
    "      RETRIES: 1\n",
    "policies:\n",
    "  - feature:\n",
    "      enabled: false\n",
    "      level: beta\n",
    "thresholds: [1, 2]\n",
    "tags: [prod, legacy]\n",
    "settings:\n",
    "  payload:\n",
    "    timeout: 30\n",
    "    retries: 2\n",
    "metadata:\n",
    "  region:\n",
    "    primary: us-east\n",
    "    backup: us-west\n",
    "  owners:\n",
    "    - Alice\n",
    "alerts:\n",
    "  - severity: low\n",
    "    code: A\n",
    "rules:\n",
    "  - rule:\n",
    "      allow: true\n",
    "      threshold: 5\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "COMPLEX_OVERRIDE_YAML = \"\"\"\n",
    "services:\n",
    "  - id: api\n",
    "    port: 80\n",
    "    env:\n",
    "      DEBUG: true\n",
    "      CACHE: false\n",
    "  - id: worker\n",
    "    port: 9000\n",
    "    env: {}\n",
    "policies:\n",
    "  - feature:\n",
    "      level: stable\n",
    "      extra: true\n",
    "thresholds: [2, 3]\n",
    "tags: [prod, blue]\n",
    "settings:\n",
    "  payload: 42\n",
    "metadata:\n",
    "  region:\n",
    "    backup: eu-west\n",
    "  owners:\n",
    "    - Alice\n",
    "    - Bob\n",
    "  notes:\n",
    "    cycling: true\n",
    "alerts:\n",
    "  - severity: medium\n",
    "    code: B\n",
    "rules:\n",
    "  - rule:\n",
    "      allow: true\n",
    "      notes: monitored\n",
    "  - rule:\n",
    "      allow: false\n",
    "      severity: critical\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "EXPECTED_COMPLEX_YAML = \"\"\"\n",
    "services:\n",
    "  - id: api\n",
    "    port: 80\n",
    "    env:\n",
    "      DEBUG: true\n",
    "      RETRIES: 1\n",
    "      CACHE: false\n",
    "  - id: worker\n",
    "    port: 9000\n",
    "    env: {}\n",
    "policies:\n",
    "  - feature:\n",
    "      enabled: false\n",
    "      level: stable\n",
    "      extra: true\n",
    "thresholds: [1, 2, 2, 3]\n",
    "tags: [prod, legacy, blue]\n",
    "settings:\n",
    "  payload: 42\n",
    "metadata:\n",
    "  region:\n",
    "    primary: us-east\n",
    "    backup: eu-west\n",
    "  owners:\n",
    "    - Alice\n",
    "    - Bob\n",
    "  notes:\n",
    "    cycling: true\n",
    "alerts:\n",
    "  - severity: low\n",
    "    code: A\n",
    "  - severity: medium\n",
    "    code: B\n",
    "rules:\n",
    "  - rule:\n",
    "      allow: false\n",
    "      threshold: 5\n",
    "      notes: monitored\n",
    "      severity: critical\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "complex_defaults = ComplexConfig.model_validate(yaml.safe_load(COMPLEX_DEFAULTS_YAML))\n",
    "\n",
    "\n",
    "complex_override = ComplexConfig.model_validate(yaml.safe_load(COMPLEX_OVERRIDE_YAML))\n",
    "\n",
    "\n",
    "expected_complex = yaml.safe_load(EXPECTED_COMPLEX_YAML)\n",
    "\n",
    "\n",
    "_assert_model_merge(\n",
    "    \"complex_configuration\",\n",
    "    complex_defaults,\n",
    "    complex_override,\n",
    "    expected_complex,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"merge_basemodels_preserving comprehensive scenario passed ✔\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a28856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">length: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>\n",
       "width: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>\n",
       "height: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "color: blue\n",
       "meta:\n",
       "  owner: Bob\n",
       "  location:\n",
       "    city: Berlin\n",
       "    country: France\n",
       "tags:\n",
       "- new\n",
       "- wooden\n",
       "material: wood\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "length: \u001b[1;36m20\u001b[0m\n",
       "width: \u001b[1;36m8\u001b[0m\n",
       "height: \u001b[1;36m3\u001b[0m\n",
       "color: blue\n",
       "meta:\n",
       "  owner: Bob\n",
       "  location:\n",
       "    city: Berlin\n",
       "    country: France\n",
       "tags:\n",
       "- new\n",
       "- wooden\n",
       "material: wood\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">length: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>\n",
       "width: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>\n",
       "height: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "color: blue\n",
       "meta:\n",
       "  owner: Bob\n",
       "  location:\n",
       "    city: Berlin\n",
       "    country: France\n",
       "tags:\n",
       "- storage\n",
       "- blue\n",
       "- nam:\n",
       "    large: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    a: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>\n",
       "- new\n",
       "- wooden\n",
       "material: wood\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "length: \u001b[1;36m20\u001b[0m\n",
       "width: \u001b[1;36m8\u001b[0m\n",
       "height: \u001b[1;36m3\u001b[0m\n",
       "color: blue\n",
       "meta:\n",
       "  owner: Bob\n",
       "  location:\n",
       "    city: Berlin\n",
       "    country: France\n",
       "tags:\n",
       "- storage\n",
       "- blue\n",
       "- nam:\n",
       "    large: \u001b[1;36m0\u001b[0m\n",
       "    a: \u001b[1;36m9\u001b[0m\n",
       "- new\n",
       "- wooden\n",
       "material: wood\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create another Box object\n",
    "b2 = Box({\n",
    "    \"length\": 20,\n",
    "    \"width\": 8,\n",
    "    \"material\": \"wood\",\n",
    "    \"meta\": {\n",
    "        \"owner\": \"Bob\",\n",
    "        \"location\": {\"city\": \"Berlin\"}\n",
    "    },\n",
    "    \"tags\": [\"new\", \"wooden\"]\n",
    "})\n",
    "\n",
    "# Merge b2 into a, overwriting in case of collision\n",
    "#c= Box(a)\n",
    "#c.merge_update(b2)\n",
    "c= a + b2  # This will concatenate lists instead of overwriting\n",
    "d = merge_boxes(a, b2)  # This will do a deep merge with custom logic\n",
    "rprint(c.to_yaml())\n",
    "rprint(d.to_yaml()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "931e227c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">a:\n",
       "  e:\n",
       "    f: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "a:\n",
       "  e:\n",
       "    f: \u001b[1;36m11\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tempbox=Box(default_box=True,box_dots=True)\n",
    "\n",
    "tempbox[\"a.e.f\"]=11\n",
    "rprint(tempbox.to_yaml())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
